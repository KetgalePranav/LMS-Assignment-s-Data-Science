{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAN\n",
    "## forestfires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANAV\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\PRANAV\\Desktop\\lms\\ANN\\forestfires.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.value_counts('month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27d6452d288>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "aug    184\n",
       "sep    172\n",
       "mar     54\n",
       "jul     32\n",
       "feb     20\n",
       "jun     17\n",
       "oct     15\n",
       "apr      9\n",
       "dec      9\n",
       "jan      2\n",
       "may      2\n",
       "nov      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = lb.fit_transform(df['size_category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('day',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('size_category',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFMC</th>\n",
       "      <td>86.2</td>\n",
       "      <td>90.6</td>\n",
       "      <td>90.6</td>\n",
       "      <td>91.7</td>\n",
       "      <td>89.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMC</th>\n",
       "      <td>26.2</td>\n",
       "      <td>35.4</td>\n",
       "      <td>43.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>51.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>94.3</td>\n",
       "      <td>669.1</td>\n",
       "      <td>686.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>102.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISI</th>\n",
       "      <td>5.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>8.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>51.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayfri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daymon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daythu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytue</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daywed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthapr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthaug</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthdec</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthfeb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthjan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthjul</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthjun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthmar</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthmay</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthnov</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthoct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthsep</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_apr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_aug</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_dec</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_feb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_jan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_jul</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_jun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_mar</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_may</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_nov</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_oct</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_sep</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2     3      4\n",
       "FFMC       86.2   90.6   90.6  91.7   89.3\n",
       "DMC        26.2   35.4   43.7  33.3   51.3\n",
       "DC         94.3  669.1  686.9  77.5  102.2\n",
       "ISI         5.1    6.7    6.7   9.0    9.6\n",
       "temp        8.2   18.0   14.6   8.3   11.4\n",
       "RH         51.0   33.0   33.0  97.0   99.0\n",
       "wind        6.7    0.9    1.3   4.0    1.8\n",
       "rain        0.0    0.0    0.0   0.2    0.0\n",
       "area        0.0    0.0    0.0   0.0    0.0\n",
       "dayfri      1.0    0.0    0.0   1.0    0.0\n",
       "daymon      0.0    0.0    0.0   0.0    0.0\n",
       "daysat      0.0    0.0    1.0   0.0    0.0\n",
       "daysun      0.0    0.0    0.0   0.0    1.0\n",
       "daythu      0.0    0.0    0.0   0.0    0.0\n",
       "daytue      0.0    1.0    0.0   0.0    0.0\n",
       "daywed      0.0    0.0    0.0   0.0    0.0\n",
       "monthapr    0.0    0.0    0.0   0.0    0.0\n",
       "monthaug    0.0    0.0    0.0   0.0    0.0\n",
       "monthdec    0.0    0.0    0.0   0.0    0.0\n",
       "monthfeb    0.0    0.0    0.0   0.0    0.0\n",
       "monthjan    0.0    0.0    0.0   0.0    0.0\n",
       "monthjul    0.0    0.0    0.0   0.0    0.0\n",
       "monthjun    0.0    0.0    0.0   0.0    0.0\n",
       "monthmar    1.0    0.0    0.0   1.0    1.0\n",
       "monthmay    0.0    0.0    0.0   0.0    0.0\n",
       "monthnov    0.0    0.0    0.0   0.0    0.0\n",
       "monthoct    0.0    1.0    1.0   0.0    0.0\n",
       "monthsep    0.0    0.0    0.0   0.0    0.0\n",
       "y           1.0    1.0    1.0   1.0    1.0\n",
       "month_apr   0.0    0.0    0.0   0.0    0.0\n",
       "month_aug   0.0    0.0    0.0   0.0    0.0\n",
       "month_dec   0.0    0.0    0.0   0.0    0.0\n",
       "month_feb   0.0    0.0    0.0   0.0    0.0\n",
       "month_jan   0.0    0.0    0.0   0.0    0.0\n",
       "month_jul   0.0    0.0    0.0   0.0    0.0\n",
       "month_jun   0.0    0.0    0.0   0.0    0.0\n",
       "month_mar   1.0    0.0    0.0   1.0    1.0\n",
       "month_may   0.0    0.0    0.0   0.0    0.0\n",
       "month_nov   0.0    0.0    0.0   0.0    0.0\n",
       "month_oct   0.0    1.0    1.0   0.0    0.0\n",
       "month_sep   0.0    0.0    0.0   0.0    0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate columns\n",
    "df=df.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y',axis=1).values\n",
    "y = df['y'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "model.add(Dense(units=28,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=14,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.4633 - val_loss: 1.5932\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8018 - val_loss: 0.5459\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4343 - val_loss: 0.3152\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3594 - val_loss: 0.3190\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2707 - val_loss: 0.2471\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2315 - val_loss: 0.2382\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2246 - val_loss: 0.2210\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.2096\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2141 - val_loss: 0.2054\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1987 - val_loss: 0.2136\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1952 - val_loss: 0.1885\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1857 - val_loss: 0.2139\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1991 - val_loss: 0.1927\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1723 - val_loss: 0.2138\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1723 - val_loss: 0.1821\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1671 - val_loss: 0.1692\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1627 - val_loss: 0.2001\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1973 - val_loss: 0.1764\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1473 - val_loss: 0.2505\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1704 - val_loss: 0.1547\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1421 - val_loss: 0.1531\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1509 - val_loss: 0.1570\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1815 - val_loss: 0.1662\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1375 - val_loss: 0.1673\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1306 - val_loss: 0.1607\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1373 - val_loss: 0.1470\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1307 - val_loss: 0.1347\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1227 - val_loss: 0.1589\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1322 - val_loss: 0.1731\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1408 - val_loss: 0.1598\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1277 - val_loss: 0.1223\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 0.1360\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1167 - val_loss: 0.1245\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1242 - val_loss: 0.1873\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1390 - val_loss: 0.1599\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1302 - val_loss: 0.1494\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1196 - val_loss: 0.1238\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1197 - val_loss: 0.1618\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1243 - val_loss: 0.1471\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0989 - val_loss: 0.1082\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0944 - val_loss: 0.1120\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1045 - val_loss: 0.1087\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0978 - val_loss: 0.1072\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0899 - val_loss: 0.1258\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1091 - val_loss: 0.1450\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1479 - val_loss: 0.1010\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1105 - val_loss: 0.0956\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1312 - val_loss: 0.1274\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1028 - val_loss: 0.0952\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0821 - val_loss: 0.0880\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0838 - val_loss: 0.0980\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0828 - val_loss: 0.0858\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0861 - val_loss: 0.1049\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1221 - val_loss: 0.0911\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1085 - val_loss: 0.0858\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0769 - val_loss: 0.0920\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1044 - val_loss: 0.0840\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0830 - val_loss: 0.0827\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0801 - val_loss: 0.0805\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0705 - val_loss: 0.1094\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1199 - val_loss: 0.0783\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0721 - val_loss: 0.1253\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0923 - val_loss: 0.1586\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1095 - val_loss: 0.0778\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0714 - val_loss: 0.0819\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0676 - val_loss: 0.1275\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0815 - val_loss: 0.0835\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0763 - val_loss: 0.1137\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0826 - val_loss: 0.0837\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0859 - val_loss: 0.0741\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0703 - val_loss: 0.0705\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0671 - val_loss: 0.0961\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1041 - val_loss: 0.0674\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0623 - val_loss: 0.0667\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0860\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0732 - val_loss: 0.0832\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0641 - val_loss: 0.0652\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0583 - val_loss: 0.0639\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0659 - val_loss: 0.0642\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0625 - val_loss: 0.0663\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0819 - val_loss: 0.1037\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0680 - val_loss: 0.0644\n",
      "Epoch 83/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0584 - val_loss: 0.0636\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0609 - val_loss: 0.0646\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0562 - val_loss: 0.0700\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0561 - val_loss: 0.0763\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0766 - val_loss: 0.1190\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0761 - val_loss: 0.0667\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0668 - val_loss: 0.0694\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0646 - val_loss: 0.0676\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0572 - val_loss: 0.0582\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0546 - val_loss: 0.0703\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0529 - val_loss: 0.0570\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0615 - val_loss: 0.0708\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.0572\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0599 - val_loss: 0.0592\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0552 - val_loss: 0.0574\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0493 - val_loss: 0.0551\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0482 - val_loss: 0.0533\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0537 - val_loss: 0.0541\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0515 - val_loss: 0.0536\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0492 - val_loss: 0.0505\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0487 - val_loss: 0.0649\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0611 - val_loss: 0.0598\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0742 - val_loss: 0.1123\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0851 - val_loss: 0.0663\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0550 - val_loss: 0.0974\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0513 - val_loss: 0.0535\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0497 - val_loss: 0.0557\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0471 - val_loss: 0.0912\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0540 - val_loss: 0.0486\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0524 - val_loss: 0.0830\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0555 - val_loss: 0.0652\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0500 - val_loss: 0.1069\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0889 - val_loss: 0.0658\n",
      "Epoch 116/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0957 - val_loss: 0.0689\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0552 - val_loss: 0.0605\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0541 - val_loss: 0.0520\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0558 - val_loss: 0.0495\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0538 - val_loss: 0.0493\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0462 - val_loss: 0.0839\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0702 - val_loss: 0.0513\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0667 - val_loss: 0.0438\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0432 - val_loss: 0.0460\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0481 - val_loss: 0.0488\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0486 - val_loss: 0.0510\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0447 - val_loss: 0.0434\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0402 - val_loss: 0.0497\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0479 - val_loss: 0.0446\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0421 - val_loss: 0.0430\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0388 - val_loss: 0.0658\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0415\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.0437\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0403\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0421 - val_loss: 0.0744\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1624 - val_loss: 0.0844\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.0394\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.0443\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0477 - val_loss: 0.0936\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.0890\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0630 - val_loss: 0.0719\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0589 - val_loss: 0.0453\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.0391\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0592\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0488 - val_loss: 0.0629\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0562 - val_loss: 0.0720\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0456 - val_loss: 0.0405\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.0368\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0423 - val_loss: 0.0428\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0401 - val_loss: 0.0525\n",
      "Epoch 151/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0623 - val_loss: 0.0467\n",
      "Epoch 152/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0506 - val_loss: 0.0659\n",
      "Epoch 153/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0688 - val_loss: 0.0865\n",
      "Epoch 154/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0553 - val_loss: 0.0353\n",
      "Epoch 155/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0335\n",
      "Epoch 156/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0837 - val_loss: 0.0421\n",
      "Epoch 157/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0384 - val_loss: 0.0330\n",
      "Epoch 158/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0394 - val_loss: 0.0305\n",
      "Epoch 159/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0328 - val_loss: 0.0340\n",
      "Epoch 160/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0408 - val_loss: 0.0415\n",
      "Epoch 161/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0521 - val_loss: 0.0780\n",
      "Epoch 162/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0491 - val_loss: 0.0612\n",
      "Epoch 163/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0677 - val_loss: 0.1277\n",
      "Epoch 164/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0482 - val_loss: 0.1006\n",
      "Epoch 165/600\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0588 - val_loss: 0.0359\n",
      "Epoch 166/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0414 - val_loss: 0.0560\n",
      "Epoch 167/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0509 - val_loss: 0.0711\n",
      "Epoch 168/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0493 - val_loss: 0.0324\n",
      "Epoch 169/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0331 - val_loss: 0.0487\n",
      "Epoch 170/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0592 - val_loss: 0.0339\n",
      "Epoch 171/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0466\n",
      "Epoch 172/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0359 - val_loss: 0.0330\n",
      "Epoch 173/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.0354\n",
      "Epoch 174/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0597\n",
      "Epoch 175/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0344\n",
      "Epoch 176/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0439\n",
      "Epoch 177/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0434 - val_loss: 0.0443\n",
      "Epoch 178/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.0337\n",
      "Epoch 179/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0350\n",
      "Epoch 180/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0612 - val_loss: 0.0488\n",
      "Epoch 181/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0371 - val_loss: 0.0626\n",
      "Epoch 182/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0411\n",
      "Epoch 183/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0455 - val_loss: 0.0623\n",
      "Epoch 184/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0344 - val_loss: 0.0317\n",
      "Epoch 185/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0459\n",
      "Epoch 186/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0340\n",
      "Epoch 187/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0322 - val_loss: 0.0408\n",
      "Epoch 188/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0347 - val_loss: 0.0338\n",
      "Epoch 189/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0313 - val_loss: 0.0321\n",
      "Epoch 190/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0339\n",
      "Epoch 191/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 192/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0318\n",
      "Epoch 193/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0437 - val_loss: 0.0571\n",
      "Epoch 194/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0786 - val_loss: 0.0325\n",
      "Epoch 195/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1083 - val_loss: 0.1224\n",
      "Epoch 196/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0829 - val_loss: 0.0397\n",
      "Epoch 197/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0419 - val_loss: 0.0374\n",
      "Epoch 198/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0371 - val_loss: 0.0396\n",
      "Epoch 199/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.0391\n",
      "Epoch 200/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0397 - val_loss: 0.0310\n",
      "Epoch 201/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0309\n",
      "Epoch 202/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0491\n",
      "Epoch 203/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0427 - val_loss: 0.0297\n",
      "Epoch 204/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0478\n",
      "Epoch 205/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.0524\n",
      "Epoch 206/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0315\n",
      "Epoch 207/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0510\n",
      "Epoch 208/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0453 - val_loss: 0.0277\n",
      "Epoch 209/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0369\n",
      "Epoch 210/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0320 - val_loss: 0.0280\n",
      "Epoch 211/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0344 - val_loss: 0.0296\n",
      "Epoch 212/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0394 - val_loss: 0.0300\n",
      "Epoch 213/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0317 - val_loss: 0.0304\n",
      "Epoch 214/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0366 - val_loss: 0.0595\n",
      "Epoch 215/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0342 - val_loss: 0.0349\n",
      "Epoch 216/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0487 - val_loss: 0.0574\n",
      "Epoch 217/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0354 - val_loss: 0.0375\n",
      "Epoch 218/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 219/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0298\n",
      "Epoch 220/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0272\n",
      "Epoch 221/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0431\n",
      "Epoch 222/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0385 - val_loss: 0.0267\n",
      "Epoch 223/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0407 - val_loss: 0.0416\n",
      "Epoch 224/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0267\n",
      "Epoch 225/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0273\n",
      "Epoch 226/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0300 - val_loss: 0.0430\n",
      "Epoch 227/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0340 - val_loss: 0.0264\n",
      "Epoch 228/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0339 - val_loss: 0.0746\n",
      "Epoch 229/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0265\n",
      "Epoch 230/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.0296\n",
      "Epoch 231/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0467\n",
      "Epoch 232/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0314\n",
      "Epoch 233/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0481 - val_loss: 0.0398\n",
      "Epoch 234/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0507 - val_loss: 0.0268\n",
      "Epoch 235/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 0.0530\n",
      "Epoch 236/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0569 - val_loss: 0.0503\n",
      "Epoch 237/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0522 - val_loss: 0.0276\n",
      "Epoch 238/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0379 - val_loss: 0.0263\n",
      "Epoch 239/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0263\n",
      "Epoch 240/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0356\n",
      "Epoch 241/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0332\n",
      "Epoch 242/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0353 - val_loss: 0.0274\n",
      "Epoch 243/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1505 - val_loss: 0.0873\n",
      "Epoch 244/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1637 - val_loss: 0.1451\n",
      "Epoch 245/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1088 - val_loss: 0.0375\n",
      "Epoch 246/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0574 - val_loss: 0.0261\n",
      "Epoch 247/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1489 - val_loss: 0.2083\n",
      "Epoch 248/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0618 - val_loss: 0.0299\n",
      "Epoch 249/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0431 - val_loss: 0.0270\n",
      "Epoch 250/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0507 - val_loss: 0.0279\n",
      "Epoch 251/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.0269\n",
      "Epoch 252/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1127 - val_loss: 0.0332\n",
      "Epoch 253/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.0406\n",
      "Epoch 254/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0472 - val_loss: 0.0555\n",
      "Epoch 255/600\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.053 - 0s 5ms/step - loss: 0.0314 - val_loss: 0.0229\n",
      "Epoch 256/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0231\n",
      "Epoch 257/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0212\n",
      "Epoch 258/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0225\n",
      "Epoch 259/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0222\n",
      "Epoch 260/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0222\n",
      "Epoch 261/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0221 - val_loss: 0.0280\n",
      "Epoch 262/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.0370\n",
      "Epoch 263/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1022 - val_loss: 0.0395\n",
      "Epoch 264/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.0252\n",
      "Epoch 265/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.0297\n",
      "Epoch 266/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0318 - val_loss: 0.0346\n",
      "Epoch 267/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0376 - val_loss: 0.0220\n",
      "Epoch 268/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.0257\n",
      "Epoch 269/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0301\n",
      "Epoch 270/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0475\n",
      "Epoch 271/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0476 - val_loss: 0.0423\n",
      "Epoch 272/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0425 - val_loss: 0.0496\n",
      "Epoch 273/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0438 - val_loss: 0.0396\n",
      "Epoch 274/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0247\n",
      "Epoch 275/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0304 - val_loss: 0.0342\n",
      "Epoch 276/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0241\n",
      "Epoch 277/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0326\n",
      "Epoch 278/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0526 - val_loss: 0.0702\n",
      "Epoch 279/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0657 - val_loss: 0.0239\n",
      "Epoch 280/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0230\n",
      "Epoch 281/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.0478\n",
      "Epoch 282/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0373 - val_loss: 0.0264\n",
      "Epoch 283/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0454 - val_loss: 0.0480\n",
      "Epoch 284/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0339 - val_loss: 0.0296\n",
      "Epoch 285/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0240\n",
      "Epoch 286/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.0267\n",
      "Epoch 287/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.0232\n",
      "Epoch 288/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0247\n",
      "Epoch 289/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.2024\n",
      "Epoch 290/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0666 - val_loss: 0.0424\n",
      "Epoch 291/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0388 - val_loss: 0.0347\n",
      "Epoch 292/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0247\n",
      "Epoch 293/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0275\n",
      "Epoch 294/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0330\n",
      "Epoch 295/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0296\n",
      "Epoch 296/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0259\n",
      "Epoch 297/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - val_loss: 0.0251\n",
      "Epoch 298/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.0539\n",
      "Epoch 299/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.1143\n",
      "Epoch 300/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0564 - val_loss: 0.0277\n",
      "Epoch 301/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0239\n",
      "Epoch 302/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0248\n",
      "Epoch 303/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0365\n",
      "Epoch 304/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0428 - val_loss: 0.0440\n",
      "Epoch 305/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0386 - val_loss: 0.0293\n",
      "Epoch 306/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0324 - val_loss: 0.0260\n",
      "Epoch 307/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0331 - val_loss: 0.0254\n",
      "Epoch 308/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0861 - val_loss: 0.0308\n",
      "Epoch 309/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3859 - val_loss: 0.5595\n",
      "Epoch 310/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2007 - val_loss: 0.1060\n",
      "Epoch 311/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0499 - val_loss: 0.0595\n",
      "Epoch 312/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0316 - val_loss: 0.0233\n",
      "Epoch 313/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0332 - val_loss: 0.0206\n",
      "Epoch 314/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0217\n",
      "Epoch 315/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0275\n",
      "Epoch 316/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0216\n",
      "Epoch 317/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0414\n",
      "Epoch 318/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0436 - val_loss: 0.0185\n",
      "Epoch 319/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.0201\n",
      "Epoch 320/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.0344\n",
      "Epoch 321/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0283\n",
      "Epoch 322/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0194\n",
      "Epoch 323/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0198\n",
      "Epoch 324/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0193\n",
      "Epoch 325/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0495 - val_loss: 0.0811\n",
      "Epoch 326/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0581 - val_loss: 0.0224\n",
      "Epoch 327/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0213\n",
      "Epoch 328/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0231\n",
      "Epoch 329/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0552\n",
      "Epoch 330/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0364 - val_loss: 0.0194\n",
      "Epoch 331/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.0359\n",
      "Epoch 332/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0387\n",
      "Epoch 333/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0263\n",
      "Epoch 334/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0202\n",
      "Epoch 335/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0265\n",
      "Epoch 336/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.0202\n",
      "Epoch 337/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 338/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0333\n",
      "Epoch 339/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0224\n",
      "Epoch 340/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 341/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0193\n",
      "Epoch 342/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.0385\n",
      "Epoch 343/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.0250\n",
      "Epoch 344/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0219\n",
      "Epoch 345/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 346/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0227\n",
      "Epoch 347/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0222\n",
      "Epoch 348/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0251\n",
      "Epoch 349/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0236\n",
      "Epoch 350/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0255\n",
      "Epoch 351/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0266\n",
      "Epoch 352/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0227\n",
      "Epoch 353/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.0272\n",
      "Epoch 354/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0251\n",
      "Epoch 355/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.0230\n",
      "Epoch 356/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0242 - val_loss: 0.0278\n",
      "Epoch 357/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0261\n",
      "Epoch 358/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0860 - val_loss: 0.1158\n",
      "Epoch 359/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0381 - val_loss: 0.0330\n",
      "Epoch 360/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0382\n",
      "Epoch 361/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0341\n",
      "Epoch 362/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0638\n",
      "Epoch 363/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0666 - val_loss: 0.0471\n",
      "Epoch 364/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1160 - val_loss: 0.0719\n",
      "Epoch 365/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0498 - val_loss: 0.0609\n",
      "Epoch 366/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0349 - val_loss: 0.0277\n",
      "Epoch 367/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0368\n",
      "Epoch 368/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0767\n",
      "Epoch 369/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0526 - val_loss: 0.0237\n",
      "Epoch 370/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0427\n",
      "Epoch 371/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.0283\n",
      "Epoch 372/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0275\n",
      "Epoch 373/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0306\n",
      "Epoch 374/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0286\n",
      "Epoch 375/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0297\n",
      "Epoch 376/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0279\n",
      "Epoch 377/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0304\n",
      "Epoch 378/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0309\n",
      "Epoch 379/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0266\n",
      "Epoch 380/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0268\n",
      "Epoch 381/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0304\n",
      "Epoch 382/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0235\n",
      "Epoch 383/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0234\n",
      "Epoch 384/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0237 - val_loss: 0.0333\n",
      "Epoch 385/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0439\n",
      "Epoch 386/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0446 - val_loss: 0.0344\n",
      "Epoch 387/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0648\n",
      "Epoch 388/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0497\n",
      "Epoch 389/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.0260\n",
      "Epoch 390/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0313\n",
      "Epoch 391/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0330\n",
      "Epoch 392/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0331\n",
      "Epoch 393/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0293 - val_loss: 0.0349\n",
      "Epoch 394/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0313\n",
      "Epoch 395/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0411\n",
      "Epoch 396/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0672\n",
      "Epoch 397/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0364 - val_loss: 0.0739\n",
      "Epoch 398/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0449 - val_loss: 0.0307\n",
      "Epoch 399/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0304\n",
      "Epoch 400/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0354\n",
      "Epoch 401/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0288 - val_loss: 0.0426\n",
      "Epoch 402/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0495\n",
      "Epoch 403/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0391\n",
      "Epoch 404/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0357\n",
      "Epoch 405/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0411\n",
      "Epoch 406/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0292\n",
      "Epoch 407/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.0427\n",
      "Epoch 408/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0374\n",
      "Epoch 409/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0307\n",
      "Epoch 410/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0458 - val_loss: 0.0311\n",
      "Epoch 411/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0303\n",
      "Epoch 412/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0285\n",
      "Epoch 413/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0288\n",
      "Epoch 414/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0323\n",
      "Epoch 415/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0357\n",
      "Epoch 416/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0457\n",
      "Epoch 417/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0256 - val_loss: 0.0538\n",
      "Epoch 418/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0291 - val_loss: 0.0472\n",
      "Epoch 419/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0400\n",
      "Epoch 420/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0388\n",
      "Epoch 421/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.0520\n",
      "Epoch 422/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0457\n",
      "Epoch 423/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0673\n",
      "Epoch 424/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0433\n",
      "Epoch 425/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.0464\n",
      "Epoch 426/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0465\n",
      "Epoch 427/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0626\n",
      "Epoch 428/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0509\n",
      "Epoch 429/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.0389\n",
      "Epoch 430/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0918\n",
      "Epoch 431/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0491\n",
      "Epoch 432/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 0.0767\n",
      "Epoch 433/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0672\n",
      "Epoch 434/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.0454\n",
      "Epoch 435/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0404\n",
      "Epoch 436/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0467\n",
      "Epoch 437/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0420\n",
      "Epoch 438/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0447\n",
      "Epoch 439/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0233 - val_loss: 0.0448\n",
      "Epoch 440/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0671\n",
      "Epoch 441/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0467 - val_loss: 0.0532\n",
      "Epoch 442/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0415\n",
      "Epoch 443/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0361\n",
      "Epoch 444/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1075 - val_loss: 0.2879\n",
      "Epoch 445/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0965 - val_loss: 0.0253\n",
      "Epoch 446/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.0261\n",
      "Epoch 447/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0347\n",
      "Epoch 448/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0337\n",
      "Epoch 449/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0297\n",
      "Epoch 450/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0351\n",
      "Epoch 451/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0316\n",
      "Epoch 452/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0695\n",
      "Epoch 453/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0344 - val_loss: 0.0406\n",
      "Epoch 454/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0386\n",
      "Epoch 455/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0377\n",
      "Epoch 456/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0386\n",
      "Epoch 457/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0444\n",
      "Epoch 458/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0377\n",
      "Epoch 459/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0374\n",
      "Epoch 460/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0368\n",
      "Epoch 461/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0377\n",
      "Epoch 462/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0362\n",
      "Epoch 463/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0364\n",
      "Epoch 464/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0460\n",
      "Epoch 465/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0385\n",
      "Epoch 466/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0520\n",
      "Epoch 467/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0392\n",
      "Epoch 468/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0455\n",
      "Epoch 469/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0462\n",
      "Epoch 470/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0440\n",
      "Epoch 471/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0477\n",
      "Epoch 472/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0430\n",
      "Epoch 473/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0450\n",
      "Epoch 474/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0452\n",
      "Epoch 475/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0408\n",
      "Epoch 476/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0546\n",
      "Epoch 477/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0398\n",
      "Epoch 478/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0396\n",
      "Epoch 479/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0456\n",
      "Epoch 480/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0430\n",
      "Epoch 481/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0443\n",
      "Epoch 482/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0729\n",
      "Epoch 483/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0423 - val_loss: 0.0428\n",
      "Epoch 484/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - val_loss: 0.0351\n",
      "Epoch 485/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0433\n",
      "Epoch 486/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0361\n",
      "Epoch 487/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0434\n",
      "Epoch 488/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0431\n",
      "Epoch 489/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0481\n",
      "Epoch 490/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0407\n",
      "Epoch 491/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0416\n",
      "Epoch 492/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0446\n",
      "Epoch 493/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0447\n",
      "Epoch 494/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0405 - val_loss: 0.0522\n",
      "Epoch 495/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0565\n",
      "Epoch 496/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0461\n",
      "Epoch 497/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0519\n",
      "Epoch 498/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0941\n",
      "Epoch 499/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.0666\n",
      "Epoch 500/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.1032\n",
      "Epoch 501/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1100 - val_loss: 0.0667\n",
      "Epoch 502/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0623 - val_loss: 0.0476\n",
      "Epoch 503/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0330 - val_loss: 0.0464\n",
      "Epoch 504/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0379\n",
      "Epoch 505/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0323\n",
      "Epoch 506/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0332\n",
      "Epoch 507/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0505\n",
      "Epoch 508/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.0763\n",
      "Epoch 509/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0292 - val_loss: 0.0552\n",
      "Epoch 510/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0490\n",
      "Epoch 511/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0484\n",
      "Epoch 512/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0550\n",
      "Epoch 513/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0513\n",
      "Epoch 514/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0777\n",
      "Epoch 515/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2015 - val_loss: 0.4201\n",
      "Epoch 516/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1265 - val_loss: 0.0406\n",
      "Epoch 517/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0482\n",
      "Epoch 518/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1186 - val_loss: 0.2175\n",
      "Epoch 519/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1336 - val_loss: 0.0790\n",
      "Epoch 520/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.0612\n",
      "Epoch 521/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0428 - val_loss: 0.0823\n",
      "Epoch 522/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0378 - val_loss: 0.0339\n",
      "Epoch 523/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0356\n",
      "Epoch 524/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0408\n",
      "Epoch 525/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0382\n",
      "Epoch 526/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0349\n",
      "Epoch 527/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0352\n",
      "Epoch 528/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0502\n",
      "Epoch 529/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0521 - val_loss: 0.1439\n",
      "Epoch 530/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1020 - val_loss: 0.0262\n",
      "Epoch 531/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0497 - val_loss: 0.1593\n",
      "Epoch 532/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0809 - val_loss: 0.0307\n",
      "Epoch 533/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0334\n",
      "Epoch 534/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0379\n",
      "Epoch 535/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0452\n",
      "Epoch 536/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0399\n",
      "Epoch 537/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0375\n",
      "Epoch 538/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0435\n",
      "Epoch 539/600\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0576 - val_loss: 0.0697\n",
      "Epoch 540/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0528\n",
      "Epoch 541/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0393\n",
      "Epoch 542/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0400\n",
      "Epoch 543/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0401\n",
      "Epoch 544/600\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0453\n",
      "Epoch 545/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0483\n",
      "Epoch 546/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0340 - val_loss: 0.0364\n",
      "Epoch 547/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0607 - val_loss: 0.0798\n",
      "Epoch 548/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0520\n",
      "Epoch 549/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0406\n",
      "Epoch 550/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0431\n",
      "Epoch 551/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0393\n",
      "Epoch 552/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0489\n",
      "Epoch 553/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0776\n",
      "Epoch 554/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1512 - val_loss: 0.1729\n",
      "Epoch 555/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0715 - val_loss: 0.0292\n",
      "Epoch 556/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0210 - val_loss: 0.0594\n",
      "Epoch 557/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0360\n",
      "Epoch 558/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0339\n",
      "Epoch 559/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0354\n",
      "Epoch 560/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0351\n",
      "Epoch 561/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0424\n",
      "Epoch 562/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0391\n",
      "Epoch 563/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0409\n",
      "Epoch 564/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0499\n",
      "Epoch 565/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0474\n",
      "Epoch 566/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0445\n",
      "Epoch 567/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0437\n",
      "Epoch 568/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0428\n",
      "Epoch 569/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0467\n",
      "Epoch 570/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0426\n",
      "Epoch 571/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0411\n",
      "Epoch 572/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0422\n",
      "Epoch 573/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0426\n",
      "Epoch 574/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0405\n",
      "Epoch 575/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0389\n",
      "Epoch 576/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0395\n",
      "Epoch 577/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0375\n",
      "Epoch 578/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.0369\n",
      "Epoch 579/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0394\n",
      "Epoch 580/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0432\n",
      "Epoch 581/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0457\n",
      "Epoch 582/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0453\n",
      "Epoch 583/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0447\n",
      "Epoch 584/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0939\n",
      "Epoch 585/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0482\n",
      "Epoch 586/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0444\n",
      "Epoch 587/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0425\n",
      "Epoch 588/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0422\n",
      "Epoch 589/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0500\n",
      "Epoch 590/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0405\n",
      "Epoch 591/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0467\n",
      "Epoch 592/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0373\n",
      "Epoch 593/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0413\n",
      "Epoch 594/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0362\n",
      "Epoch 595/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0359\n",
      "Epoch 596/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0369\n",
      "Epoch 597/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.0343\n",
      "Epoch 598/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0348\n",
      "Epoch 599/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0343\n",
      "Epoch 600/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d7487b708>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27d75b0e648>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-4aec9e43bf2d>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97        39\n",
      "         1.0       1.00      0.98      0.99        91\n",
      "\n",
      "    accuracy                           0.98       130\n",
      "   macro avg       0.98      0.99      0.98       130\n",
      "weighted avg       0.99      0.98      0.98       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 24.6374 - val_loss: 13.5919\n",
      "Epoch 2/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.9406 - val_loss: 4.7378\n",
      "Epoch 3/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9812 - val_loss: 4.2025\n",
      "Epoch 4/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.6532 - val_loss: 2.0190\n",
      "Epoch 5/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6508 - val_loss: 1.0586\n",
      "Epoch 6/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7539 - val_loss: 0.4886\n",
      "Epoch 7/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4280 - val_loss: 0.4727\n",
      "Epoch 8/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3401 - val_loss: 0.4140\n",
      "Epoch 9/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2920 - val_loss: 0.4082\n",
      "Epoch 10/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3371 - val_loss: 0.4408\n",
      "Epoch 11/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3083 - val_loss: 0.4089\n",
      "Epoch 12/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2788 - val_loss: 0.3932\n",
      "Epoch 13/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2529 - val_loss: 0.4374\n",
      "Epoch 14/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2792 - val_loss: 0.3385\n",
      "Epoch 15/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2648 - val_loss: 0.3780\n",
      "Epoch 16/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2752 - val_loss: 0.3375\n",
      "Epoch 17/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2125 - val_loss: 0.3128\n",
      "Epoch 18/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2168 - val_loss: 0.3468\n",
      "Epoch 19/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2460 - val_loss: 0.3043\n",
      "Epoch 20/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3091 - val_loss: 0.3224\n",
      "Epoch 21/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2472 - val_loss: 0.2763\n",
      "Epoch 22/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2075 - val_loss: 0.2799\n",
      "Epoch 23/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.2551\n",
      "Epoch 24/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1937 - val_loss: 0.2325\n",
      "Epoch 25/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2236 - val_loss: 0.2902\n",
      "Epoch 26/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1870 - val_loss: 0.2405\n",
      "Epoch 27/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2310 - val_loss: 0.2269\n",
      "Epoch 28/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1634 - val_loss: 0.2191\n",
      "Epoch 29/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1665 - val_loss: 0.2657\n",
      "Epoch 30/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1719 - val_loss: 0.2319\n",
      "Epoch 31/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1759 - val_loss: 0.2292\n",
      "Epoch 32/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1537 - val_loss: 0.2157\n",
      "Epoch 33/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1468 - val_loss: 0.2161\n",
      "Epoch 34/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1775 - val_loss: 0.2409\n",
      "Epoch 35/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1822 - val_loss: 0.2048\n",
      "Epoch 36/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1481 - val_loss: 0.2054\n",
      "Epoch 37/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1340 - val_loss: 0.2321\n",
      "Epoch 38/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1312 - val_loss: 0.2367\n",
      "Epoch 39/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1803 - val_loss: 0.1954\n",
      "Epoch 40/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2125 - val_loss: 0.3766\n",
      "Epoch 41/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2275 - val_loss: 0.3808\n",
      "Epoch 42/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1970 - val_loss: 0.2775\n",
      "Epoch 43/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2259 - val_loss: 0.2500\n",
      "Epoch 44/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1612 - val_loss: 0.1734\n",
      "Epoch 45/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1121 - val_loss: 0.2402\n",
      "Epoch 46/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1568 - val_loss: 0.1653\n",
      "Epoch 47/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2924 - val_loss: 0.4223\n",
      "Epoch 48/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1796 - val_loss: 0.1843\n",
      "Epoch 49/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1129 - val_loss: 0.2296\n",
      "Epoch 50/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1876 - val_loss: 0.1644\n",
      "Epoch 51/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1219 - val_loss: 0.1461\n",
      "Epoch 52/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1276 - val_loss: 0.1817\n",
      "Epoch 53/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1238 - val_loss: 0.1558\n",
      "Epoch 54/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1084 - val_loss: 0.1638\n",
      "Epoch 55/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1163 - val_loss: 0.1543\n",
      "Epoch 56/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0959 - val_loss: 0.1409\n",
      "Epoch 57/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0957 - val_loss: 0.1307\n",
      "Epoch 58/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1385 - val_loss: 0.2781\n",
      "Epoch 59/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1291 - val_loss: 0.1331\n",
      "Epoch 60/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.1283\n",
      "Epoch 61/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.2047\n",
      "Epoch 62/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1619 - val_loss: 0.2340\n",
      "Epoch 63/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3017 - val_loss: 0.3820\n",
      "Epoch 64/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2101 - val_loss: 0.2135\n",
      "Epoch 65/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1926 - val_loss: 0.2143\n",
      "Epoch 66/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1525 - val_loss: 0.1743\n",
      "Epoch 67/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4271 - val_loss: 0.5628\n",
      "Epoch 68/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4965 - val_loss: 0.1483\n",
      "Epoch 69/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2217 - val_loss: 0.1731\n",
      "Epoch 70/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2756 - val_loss: 0.3318\n",
      "Epoch 71/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3581 - val_loss: 0.3503\n",
      "Epoch 72/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2639 - val_loss: 0.1996\n",
      "Epoch 73/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1169 - val_loss: 0.1015\n",
      "Epoch 74/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0673 - val_loss: 0.0995\n",
      "Epoch 75/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0698 - val_loss: 0.1051\n",
      "Epoch 76/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0877 - val_loss: 0.1346\n",
      "Epoch 77/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0899 - val_loss: 0.1036\n",
      "Epoch 78/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0691 - val_loss: 0.1080\n",
      "Epoch 79/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0696 - val_loss: 0.0993\n",
      "Epoch 80/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0667 - val_loss: 0.0947\n",
      "Epoch 81/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0728 - val_loss: 0.0979\n",
      "Epoch 82/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1294 - val_loss: 0.1116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1064 - val_loss: 0.1829\n",
      "Epoch 84/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1226 - val_loss: 0.1511\n",
      "Epoch 85/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0928\n",
      "Epoch 86/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0602 - val_loss: 0.1260\n",
      "Epoch 87/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0767 - val_loss: 0.1162\n",
      "Epoch 88/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.1000\n",
      "Epoch 89/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1509 - val_loss: 0.1056\n",
      "Epoch 90/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0765 - val_loss: 0.0903\n",
      "Epoch 91/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0586 - val_loss: 0.0917\n",
      "Epoch 92/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0608 - val_loss: 0.0898\n",
      "Epoch 93/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0571 - val_loss: 0.0880\n",
      "Epoch 94/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.0874\n",
      "Epoch 95/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0594 - val_loss: 0.0902\n",
      "Epoch 96/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.0902\n",
      "Epoch 97/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0675 - val_loss: 0.1955\n",
      "Epoch 98/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1210 - val_loss: 0.1628\n",
      "Epoch 99/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0737 - val_loss: 0.0985\n",
      "Epoch 100/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0566 - val_loss: 0.0845\n",
      "Epoch 101/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0611 - val_loss: 0.0820\n",
      "Epoch 102/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0564 - val_loss: 0.0796\n",
      "Epoch 103/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0586 - val_loss: 0.0804\n",
      "Epoch 104/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.0786\n",
      "Epoch 105/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0593 - val_loss: 0.0784\n",
      "Epoch 106/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0658 - val_loss: 0.2824\n",
      "Epoch 107/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4759 - val_loss: 0.6083\n",
      "Epoch 108/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2791 - val_loss: 0.2374\n",
      "Epoch 109/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0913 - val_loss: 0.0997\n",
      "Epoch 110/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0824 - val_loss: 0.1197\n",
      "Epoch 111/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0618 - val_loss: 0.0733\n",
      "Epoch 112/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0512 - val_loss: 0.1036\n",
      "Epoch 113/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0618 - val_loss: 0.0834\n",
      "Epoch 114/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0734 - val_loss: 0.0987\n",
      "Epoch 115/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0870 - val_loss: 0.0747\n",
      "Epoch 116/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0596 - val_loss: 0.0745\n",
      "Epoch 117/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0753\n",
      "Epoch 118/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0582 - val_loss: 0.0776\n",
      "Epoch 119/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1547 - val_loss: 0.0902\n",
      "Epoch 120/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0545 - val_loss: 0.0980\n",
      "Epoch 121/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0586 - val_loss: 0.0731\n",
      "Epoch 122/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0562 - val_loss: 0.0885\n",
      "Epoch 123/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0746 - val_loss: 0.0977\n",
      "Epoch 124/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0710\n",
      "Epoch 125/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0695\n",
      "Epoch 126/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.1488\n",
      "Epoch 127/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0790 - val_loss: 0.1077\n",
      "Epoch 128/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.1703\n",
      "Epoch 129/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0734 - val_loss: 0.0804\n",
      "Epoch 130/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0673 - val_loss: 0.0674\n",
      "Epoch 131/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.0802\n",
      "Epoch 132/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0501 - val_loss: 0.0655\n",
      "Epoch 133/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0495 - val_loss: 0.1115\n",
      "Epoch 134/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0633 - val_loss: 0.0662\n",
      "Epoch 135/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0469 - val_loss: 0.0862\n",
      "Epoch 136/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.0708\n",
      "Epoch 137/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0580 - val_loss: 0.0793\n",
      "Epoch 138/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0530 - val_loss: 0.0646\n",
      "Epoch 139/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.0855\n",
      "Epoch 140/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0461 - val_loss: 0.0631\n",
      "Epoch 141/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.1001\n",
      "Epoch 142/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0828 - val_loss: 0.0855\n",
      "Epoch 143/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0761 - val_loss: 0.1106\n",
      "Epoch 144/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0644 - val_loss: 0.0645\n",
      "Epoch 145/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.0781\n",
      "Epoch 146/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0540 - val_loss: 0.0878\n",
      "Epoch 147/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0677 - val_loss: 0.0664\n",
      "Epoch 148/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0496 - val_loss: 0.0654\n",
      "Epoch 149/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0438 - val_loss: 0.0636\n",
      "Epoch 150/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.0709\n",
      "Epoch 151/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0523 - val_loss: 0.0655\n",
      "Epoch 152/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0437 - val_loss: 0.0885\n",
      "Epoch 153/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0490 - val_loss: 0.0876\n",
      "Epoch 154/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0598 - val_loss: 0.0765\n",
      "Epoch 155/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0453 - val_loss: 0.0657\n",
      "Epoch 156/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.0613\n",
      "Epoch 157/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0666\n",
      "Epoch 158/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0411 - val_loss: 0.0607\n",
      "Epoch 159/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0473 - val_loss: 0.0587\n",
      "Epoch 160/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0783\n",
      "Epoch 161/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.1474\n",
      "Epoch 162/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1257 - val_loss: 0.1726\n",
      "Epoch 163/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1187\n",
      "Epoch 164/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0918 - val_loss: 0.0888\n",
      "Epoch 165/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.1419\n",
      "Epoch 166/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0590 - val_loss: 0.0852\n",
      "Epoch 167/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0590 - val_loss: 0.0666\n",
      "Epoch 168/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0403 - val_loss: 0.0533\n",
      "Epoch 169/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.0643\n",
      "Epoch 170/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0934 - val_loss: 0.0880\n",
      "Epoch 171/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0404 - val_loss: 0.0931\n",
      "Epoch 172/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0504 - val_loss: 0.0621\n",
      "Epoch 173/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0417 - val_loss: 0.0757\n",
      "Epoch 174/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0912 - val_loss: 0.0821\n",
      "Epoch 175/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1039 - val_loss: 0.2677\n",
      "Epoch 176/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2362 - val_loss: 0.2394\n",
      "Epoch 177/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1647 - val_loss: 0.0545\n",
      "Epoch 178/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.0555\n",
      "Epoch 179/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0327 - val_loss: 0.0648\n",
      "Epoch 180/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.0835\n",
      "Epoch 181/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0688 - val_loss: 0.1022\n",
      "Epoch 182/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0900 - val_loss: 0.0586\n",
      "Epoch 183/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0477 - val_loss: 0.0605\n",
      "Epoch 184/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0527 - val_loss: 0.1723\n",
      "Epoch 185/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2956 - val_loss: 0.1971\n",
      "Epoch 186/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2303 - val_loss: 0.2247\n",
      "Epoch 187/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1738 - val_loss: 0.1156\n",
      "Epoch 188/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1326 - val_loss: 0.2616\n",
      "Epoch 189/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2262 - val_loss: 0.2176\n",
      "Epoch 190/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1134 - val_loss: 0.3697\n",
      "Epoch 191/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1700 - val_loss: 0.1428\n",
      "Epoch 192/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0673 - val_loss: 0.0461\n",
      "Epoch 193/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0445\n",
      "Epoch 194/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0447\n",
      "Epoch 195/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0585\n",
      "Epoch 196/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0438\n",
      "Epoch 197/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0475\n",
      "Epoch 198/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0444\n",
      "Epoch 199/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0441\n",
      "Epoch 200/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0484 - val_loss: 0.1475\n",
      "Epoch 201/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0571 - val_loss: 0.0515\n",
      "Epoch 202/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0447 - val_loss: 0.0681\n",
      "Epoch 203/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0585 - val_loss: 0.0989\n",
      "Epoch 204/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0859 - val_loss: 0.2511\n",
      "Epoch 205/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1036 - val_loss: 0.1815\n",
      "Epoch 206/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0881 - val_loss: 0.0429\n",
      "Epoch 207/600\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0421\n",
      "Epoch 208/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0419\n",
      "Epoch 209/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0308 - val_loss: 0.0681\n",
      "Epoch 210/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0829 - val_loss: 0.0541\n",
      "Epoch 211/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0419\n",
      "Epoch 212/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0321 - val_loss: 0.0458\n",
      "Epoch 213/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0460\n",
      "Epoch 214/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0354 - val_loss: 0.0427\n",
      "Epoch 215/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0721\n",
      "Epoch 216/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0368 - val_loss: 0.0710\n",
      "Epoch 217/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0391 - val_loss: 0.0524\n",
      "Epoch 218/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0348 - val_loss: 0.1152\n",
      "Epoch 219/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1695 - val_loss: 0.0764\n",
      "Epoch 220/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1286 - val_loss: 0.0388\n",
      "Epoch 221/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1157 - val_loss: 0.0614\n",
      "Epoch 222/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0553 - val_loss: 0.0415\n",
      "Epoch 223/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0378\n",
      "Epoch 224/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0314 - val_loss: 0.0553\n",
      "Epoch 225/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0517 - val_loss: 0.0438\n",
      "Epoch 226/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0327 - val_loss: 0.0394\n",
      "Epoch 227/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.1305\n",
      "Epoch 228/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0574 - val_loss: 0.1318\n",
      "Epoch 229/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1697 - val_loss: 0.0617\n",
      "Epoch 230/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0341 - val_loss: 0.0384\n",
      "Epoch 231/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 0.0425\n",
      "Epoch 232/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0319 - val_loss: 0.0377\n",
      "Epoch 233/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.0684\n",
      "Epoch 234/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2353 - val_loss: 0.1787\n",
      "Epoch 235/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1888 - val_loss: 0.0448\n",
      "Epoch 236/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0935 - val_loss: 0.0494\n",
      "Epoch 237/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.0937\n",
      "Epoch 238/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0583 - val_loss: 0.0980\n",
      "Epoch 239/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0655 - val_loss: 0.0676\n",
      "Epoch 240/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.0359\n",
      "Epoch 241/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0470\n",
      "Epoch 242/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0369\n",
      "Epoch 243/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0373\n",
      "Epoch 244/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0476\n",
      "Epoch 245/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0365\n",
      "Epoch 246/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0384\n",
      "Epoch 247/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.0376\n",
      "Epoch 248/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 0.0396\n",
      "Epoch 249/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0357\n",
      "Epoch 250/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0356\n",
      "Epoch 251/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0373 - val_loss: 0.0449\n",
      "Epoch 252/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0370 - val_loss: 0.0354\n",
      "Epoch 253/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0471\n",
      "Epoch 254/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0433 - val_loss: 0.0818\n",
      "Epoch 255/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.1135\n",
      "Epoch 256/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0775 - val_loss: 0.0624\n",
      "Epoch 257/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0571 - val_loss: 0.0454\n",
      "Epoch 258/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0519 - val_loss: 0.0862\n",
      "Epoch 259/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0581 - val_loss: 0.0807\n",
      "Epoch 260/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.1201\n",
      "Epoch 261/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1456 - val_loss: 0.1974\n",
      "Epoch 262/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1067 - val_loss: 0.0580\n",
      "Epoch 263/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.0384\n",
      "Epoch 264/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0338\n",
      "Epoch 265/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0429\n",
      "Epoch 266/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0539\n",
      "Epoch 267/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0345\n",
      "Epoch 268/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.0376\n",
      "Epoch 269/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0553\n",
      "Epoch 270/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0355\n",
      "Epoch 271/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 0.0406\n",
      "Epoch 272/600\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.0352\n",
      "Epoch 273/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0419\n",
      "Epoch 274/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.0393\n",
      "Epoch 275/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0348\n",
      "Epoch 276/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.0361\n",
      "Epoch 277/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0309 - val_loss: 0.0533\n",
      "Epoch 278/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.0940\n",
      "Epoch 279/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2012 - val_loss: 0.0962\n",
      "Epoch 280/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1094 - val_loss: 0.0352\n",
      "Epoch 281/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0585 - val_loss: 0.0398\n",
      "Epoch 282/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0306 - val_loss: 0.0437\n",
      "Epoch 283/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0548\n",
      "Epoch 284/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0430\n",
      "Epoch 285/600\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0336 - val_loss: 0.0543\n",
      "Epoch 286/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0418 - val_loss: 0.0916\n",
      "Epoch 287/600\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0660 - val_loss: 0.0719\n",
      "Epoch 288/600\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0346 - val_loss: 0.0388\n",
      "Epoch 289/600\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0646\n",
      "Epoch 00289: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d75c17988>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27d76d408c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95        39\n",
      "         1.0       0.96      1.00      0.98        91\n",
      "\n",
      "    accuracy                           0.97       130\n",
      "   macro avg       0.98      0.95      0.96       130\n",
      "weighted avg       0.97      0.97      0.97       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
